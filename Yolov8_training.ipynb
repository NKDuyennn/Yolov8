{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":21993,"status":"ok","timestamp":1699808137261,"user":{"displayName":"Dowis","userId":"18108172807253778035"},"user_tz":-420},"id":"IHaQ-IAzFlTc","outputId":"7dbbe137-21fe-41f2-a617-1b79d63d889f"},"outputs":[{"name":"stdout","output_type":"stream","text":["Mounted at /content/drive\n"]}],"source":["# Ket noi voi drive\n","from google.colab import drive\n","\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":317,"status":"ok","timestamp":1699808139420,"user":{"displayName":"Dowis","userId":"18108172807253778035"},"user_tz":-420},"id":"l5jFfQ_OF1lU","outputId":"83642e2d-bf05-42cb-a4d5-2560930d730d"},"outputs":[{"name":"stdout","output_type":"stream","text":["/content/drive/MyDrive\n"]}],"source":["%cd /content/drive/MyDrive"]},{"cell_type":"markdown","metadata":{"id":"xoN36Qw0F5xE"},"source":["# 1.Preparing Dataset"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"0W9bOiElPysk"},"outputs":[],"source":["!gdown #link tai du lieu"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ZqndQjgyP3Ml"},"outputs":[],"source":["!unrar x /content/drive/MyDrive/human_detection_dataset.rar"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ZPRuvUnOP-ME"},"outputs":[],"source":["# cau truc lai thu muc train\n","%cd # thu muc muon tao thu muc train\n","!mkdir train\n","!mkdir train/images\n","!mkdir train/labels\n","!mv *.jpg train/images\n","!mv *.txt train/labels"]},{"cell_type":"code","execution_count":9,"metadata":{"executionInfo":{"elapsed":371,"status":"ok","timestamp":1699804859723,"user":{"displayName":"Dowis","userId":"18108172807253778035"},"user_tz":-420},"id":"SwW6joGFQZZz"},"outputs":[],"source":["# File .yaml\n","import yaml\n","\n","data_info = {\n","    'train' : '/content/drive/MyDrive/human_detection_dataset/train/images',\n","    'val' : '/content/drive/MyDrive/human_detection_dataset/val/images',\n","    'nc' : 1,\n","    'names' : ['Human']\n","}\n","\n","yaml_savePath = '/content/drive/MyDrive/human_detection_dataset/data.yaml'\n","\n","with open(yaml_savePath, 'w+') as f:\n","  doc = yaml.dump(\n","      data_info, f, default_flow_style=None, sort_keys=False\n","  )"]},{"cell_type":"markdown","metadata":{"id":"9yOyMixzF9cX"},"source":["# 2.Install yolov8"]},{"cell_type":"code","execution_count":10,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":5479,"status":"ok","timestamp":1699804915654,"user":{"displayName":"Dowis","userId":"18108172807253778035"},"user_tz":-420},"id":"lcazh5PqRDKh","outputId":"f5668d6b-9864-4ad3-deb5-353ffc0b9559"},"outputs":[{"name":"stdout","output_type":"stream","text":["Cloning into 'ultralytics'...\n","remote: Enumerating objects: 17588, done.\u001b[K\n","remote: Counting objects: 100% (500/500), done.\u001b[K\n","remote: Compressing objects: 100% (310/310), done.\u001b[K\n","remote: Total 17588 (delta 292), reused 329 (delta 189), pack-reused 17088\u001b[K\n","Receiving objects: 100% (17588/17588), 9.40 MiB | 12.26 MiB/s, done.\n","Resolving deltas: 100% (12237/12237), done.\n","Updating files: 100% (471/471), done.\n"]}],"source":["!git clone https://github.com/ultralytics/ultralytics.git"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"h6RUd6ujROEM"},"outputs":[],"source":["# Cach 1\n","%cd ultralytics\n","!pip install ultralytics"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"3bf9Ie_tRZQ5"},"outputs":[],"source":["# Cach 2\n","!pip install e ."]},{"cell_type":"markdown","metadata":{"id":"U1jCEQ-TGBGr"},"source":["# 3. Download Pretrained Model"]},{"cell_type":"code","execution_count":13,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":329,"status":"ok","timestamp":1699813493546,"user":{"displayName":"Dowis","userId":"18108172807253778035"},"user_tz":-420},"id":"CSC2IYsWRxVr","outputId":"58d95575-6562-45f4-c232-8c937c56f2f4"},"outputs":[{"name":"stdout","output_type":"stream","text":["/content/drive/MyDrive\n"]}],"source":["%cd .."]},{"cell_type":"code","execution_count":13,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1057,"status":"ok","timestamp":1699805087080,"user":{"displayName":"Dowis","userId":"18108172807253778035"},"user_tz":-420},"id":"l4FAlvp1Rki1","outputId":"a8aef832-3b4c-411f-befe-e459fae56e9b"},"outputs":[{"name":"stdout","output_type":"stream","text":["--2023-11-12 16:04:46--  https://github.com/ultralytics/assets/releases/download/v0.0.0/yolov8s.pt\n","Resolving github.com (github.com)... 140.82.112.3\n","Connecting to github.com (github.com)|140.82.112.3|:443... connected.\n","HTTP request sent, awaiting response... 302 Found\n","Location: https://objects.githubusercontent.com/github-production-release-asset-2e65be/521807533/404b29b7-e374-406c-ab38-7d0796e5b627?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAIWNJYAX4CSVEH53A%2F20231112%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20231112T160446Z&X-Amz-Expires=300&X-Amz-Signature=99573b0fb2f879be8fcfc11608ef65bd4b8478d3bac2a52474606f491cd7543b&X-Amz-SignedHeaders=host&actor_id=0&key_id=0&repo_id=521807533&response-content-disposition=attachment%3B%20filename%3Dyolov8s.pt&response-content-type=application%2Foctet-stream [following]\n","--2023-11-12 16:04:46--  https://objects.githubusercontent.com/github-production-release-asset-2e65be/521807533/404b29b7-e374-406c-ab38-7d0796e5b627?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAIWNJYAX4CSVEH53A%2F20231112%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20231112T160446Z&X-Amz-Expires=300&X-Amz-Signature=99573b0fb2f879be8fcfc11608ef65bd4b8478d3bac2a52474606f491cd7543b&X-Amz-SignedHeaders=host&actor_id=0&key_id=0&repo_id=521807533&response-content-disposition=attachment%3B%20filename%3Dyolov8s.pt&response-content-type=application%2Foctet-stream\n","Resolving objects.githubusercontent.com (objects.githubusercontent.com)... 185.199.110.133, 185.199.108.133, 185.199.109.133, ...\n","Connecting to objects.githubusercontent.com (objects.githubusercontent.com)|185.199.110.133|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 22573363 (22M) [application/octet-stream]\n","Saving to: ‘yolov8s.pt’\n","\n","yolov8s.pt          100%[===================>]  21.53M  47.3MB/s    in 0.5s    \n","\n","2023-11-12 16:04:46 (47.3 MB/s) - ‘yolov8s.pt’ saved [22573363/22573363]\n","\n"]}],"source":["!wget https://github.com/ultralytics/assets/releases/download/v0.0.0/yolov8s.pt"]},{"cell_type":"markdown","metadata":{"id":"whQRxQsoGIH-"},"source":["# 4.Training"]},{"cell_type":"code","execution_count":11,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":334968,"status":"ok","timestamp":1699811236864,"user":{"displayName":"Dowis","userId":"18108172807253778035"},"user_tz":-420},"id":"SbhucWTOR4VL","outputId":"677b1e45-c5c8-4058-c911-c8e597ec4d86"},"outputs":[{"name":"stdout","output_type":"stream","text":["Ultralytics YOLOv8.0.208 🚀 Python-3.10.12 torch-2.1.0+cu118 CUDA:0 (Tesla T4, 15102MiB)\n","\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=detect, mode=train, model=/content/drive/MyDrive/yolov8s.pt, data=/content/drive/MyDrive/human_detection_dataset/data.yaml, epochs=1, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=None, workers=8, project=None, name=train5, exist_ok=False, pretrained=True, optimizer=auto, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, show=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, vid_stride=1, stream_buffer=False, line_width=None, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, boxes=True, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/detect/train5\n","2023-11-12 17:41:45.189007: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:9342] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n","2023-11-12 17:41:45.189072: E tensorflow/compiler/xla/stream_executor/cuda/cuda_fft.cc:609] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n","2023-11-12 17:41:45.189107: E tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:1518] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","Overriding model.yaml nc=80 with nc=1\n","\n","                   from  n    params  module                                       arguments                     \n","  0                  -1  1       928  ultralytics.nn.modules.conv.Conv             [3, 32, 3, 2]                 \n","  1                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n","  2                  -1  1     29056  ultralytics.nn.modules.block.C2f             [64, 64, 1, True]             \n","  3                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n","  4                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n","  5                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n","  6                  -1  2    788480  ultralytics.nn.modules.block.C2f             [256, 256, 2, True]           \n","  7                  -1  1   1180672  ultralytics.nn.modules.conv.Conv             [256, 512, 3, 2]              \n","  8                  -1  1   1838080  ultralytics.nn.modules.block.C2f             [512, 512, 1, True]           \n","  9                  -1  1    656896  ultralytics.nn.modules.block.SPPF            [512, 512, 5]                 \n"," 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n"," 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 12                  -1  1    591360  ultralytics.nn.modules.block.C2f             [768, 256, 1]                 \n"," 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n"," 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 15                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n"," 16                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n"," 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 18                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n"," 19                  -1  1    590336  ultralytics.nn.modules.conv.Conv             [256, 256, 3, 2]              \n"," 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 21                  -1  1   1969152  ultralytics.nn.modules.block.C2f             [768, 512, 1]                 \n"," 22        [15, 18, 21]  1   2116435  ultralytics.nn.modules.head.Detect           [1, [128, 256, 512]]          \n","Model summary: 225 layers, 11135987 parameters, 11135971 gradients, 28.6 GFLOPs\n","\n","Transferred 349/355 items from pretrained weights\n","\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/detect/train5', view at http://localhost:6006/\n","Freezing layer 'model.22.dfl.conv.weight'\n","\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n","\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n","\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/drive/MyDrive/human_detection_dataset/train/labels.cache... 2220 images, 0 backgrounds, 0 corrupt: 100% 2220/2220 [00:00<?, ?it/s]\n","\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n","\u001b[34m\u001b[1mval: \u001b[0mScanning /content/drive/MyDrive/human_detection_dataset/val/labels.cache... 1642 images, 0 backgrounds, 0 corrupt: 100% 1642/1642 [00:00<?, ?it/s]\n","Plotting labels to runs/detect/train5/labels.jpg... \n","\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n","\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.002, momentum=0.9) with parameter groups 57 weight(decay=0.0), 64 weight(decay=0.0005), 63 bias(decay=0.0)\n","Image sizes 640 train, 640 val\n","Using 2 dataloader workers\n","Logging results to \u001b[1mruns/detect/train5\u001b[0m\n","Starting training for 1 epochs...\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","        1/1      4.01G       1.06      0.895      1.061        152        640: 100% 139/139 [02:11<00:00,  1.06it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 52/52 [01:11<00:00,  1.38s/it]\n","                   all       1642      13171      0.684      0.618      0.659      0.402\n","\n","1 epochs completed in 0.061 hours.\n","Optimizer stripped from runs/detect/train5/weights/last.pt, 22.5MB\n","Optimizer stripped from runs/detect/train5/weights/best.pt, 22.5MB\n","\n","Validating runs/detect/train5/weights/best.pt...\n","Ultralytics YOLOv8.0.208 🚀 Python-3.10.12 torch-2.1.0+cu118 CUDA:0 (Tesla T4, 15102MiB)\n","Model summary (fused): 168 layers, 11125971 parameters, 0 gradients, 28.4 GFLOPs\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 52/52 [01:10<00:00,  1.35s/it]\n","                   all       1642      13171      0.683      0.618      0.659      0.403\n","Speed: 0.2ms preprocess, 3.1ms inference, 0.0ms loss, 2.6ms postprocess per image\n","Results saved to \u001b[1mruns/detect/train5\u001b[0m\n","💡 Learn more at https://docs.ultralytics.com/modes/train\n"]}],"source":["# Training with CLI\n","!yolo task=detect mode=train model=/content/drive/MyDrive/yolov8s.pt data=/content/drive/MyDrive/human_detection_dataset/data.yaml epochs=1 imgsz=640"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"G53YE28uzOmv"},"outputs":[],"source":["# Training with python API\n","from ultralytics import YOLO\n","\n","model = YOLO(\"/content/drive/MyDrive/yolov8s.pt\")\n","results = model.train(data=\"/content/drive/MyDrive/human_detection_dataset/data.yaml\", epochs=1, imgsz=640)"]},{"cell_type":"markdown","metadata":{"id":"PktrtpKHGKfg"},"source":["# 5.Validating"]},{"cell_type":"code","execution_count":18,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":82294,"status":"ok","timestamp":1699815331686,"user":{"displayName":"Dowis","userId":"18108172807253778035"},"user_tz":-420},"id":"Exmy2vCozoO_","outputId":"b132db13-e3f8-4e7e-b42a-88cc4d30da05"},"outputs":[{"name":"stdout","output_type":"stream","text":["Ultralytics YOLOv8.0.208 🚀 Python-3.10.12 torch-2.1.0+cu118 CUDA:0 (Tesla T4, 15102MiB)\n","Model summary (fused): 168 layers, 11125971 parameters, 0 gradients, 28.4 GFLOPs\n","\u001b[34m\u001b[1mval: \u001b[0mScanning /content/drive/MyDrive/human_detection_dataset/val/labels.cache... 1642 images, 0 backgrounds, 0 corrupt: 100% 1642/1642 [00:00<?, ?it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 103/103 [01:11<00:00,  1.45it/s]\n","                   all       1642      13171      0.683      0.619      0.659      0.403\n","Speed: 0.2ms preprocess, 5.7ms inference, 0.0ms loss, 2.0ms postprocess per image\n","Results saved to \u001b[1mruns/detect/val\u001b[0m\n","💡 Learn more at https://docs.ultralytics.com/modes/val\n"]}],"source":["!yolo task=detect mode=val model=/content/drive/MyDrive/runs/detect/train5/weights/best.pt data=/content/drive/MyDrive/human_detection_dataset/data.yaml"]},{"cell_type":"markdown","metadata":{"id":"sUFXu00FGN9x"},"source":["# 6.Predict"]},{"cell_type":"code","execution_count":19,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":91},"executionInfo":{"elapsed":30735,"status":"ok","timestamp":1699815717949,"user":{"displayName":"Dowis","userId":"18108172807253778035"},"user_tz":-420},"id":"bbqEbX-A5-1S","outputId":"e6e3820b-5ecd-4187-dc92-9bbf603461df"},"outputs":[{"data":{"text/html":["\n","     <input type=\"file\" id=\"files-ef0d7627-f52d-41f0-904a-338d1f4cda6b\" name=\"files[]\" multiple disabled\n","        style=\"border:none\" />\n","     <output id=\"result-ef0d7627-f52d-41f0-904a-338d1f4cda6b\">\n","      Upload widget is only available when the cell has been executed in the\n","      current browser session. Please rerun this cell to enable.\n","      </output>\n","      <script>// Copyright 2017 Google LLC\n","//\n","// Licensed under the Apache License, Version 2.0 (the \"License\");\n","// you may not use this file except in compliance with the License.\n","// You may obtain a copy of the License at\n","//\n","//      http://www.apache.org/licenses/LICENSE-2.0\n","//\n","// Unless required by applicable law or agreed to in writing, software\n","// distributed under the License is distributed on an \"AS IS\" BASIS,\n","// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n","// See the License for the specific language governing permissions and\n","// limitations under the License.\n","\n","/**\n"," * @fileoverview Helpers for google.colab Python module.\n"," */\n","(function(scope) {\n","function span(text, styleAttributes = {}) {\n","  const element = document.createElement('span');\n","  element.textContent = text;\n","  for (const key of Object.keys(styleAttributes)) {\n","    element.style[key] = styleAttributes[key];\n","  }\n","  return element;\n","}\n","\n","// Max number of bytes which will be uploaded at a time.\n","const MAX_PAYLOAD_SIZE = 100 * 1024;\n","\n","function _uploadFiles(inputId, outputId) {\n","  const steps = uploadFilesStep(inputId, outputId);\n","  const outputElement = document.getElementById(outputId);\n","  // Cache steps on the outputElement to make it available for the next call\n","  // to uploadFilesContinue from Python.\n","  outputElement.steps = steps;\n","\n","  return _uploadFilesContinue(outputId);\n","}\n","\n","// This is roughly an async generator (not supported in the browser yet),\n","// where there are multiple asynchronous steps and the Python side is going\n","// to poll for completion of each step.\n","// This uses a Promise to block the python side on completion of each step,\n","// then passes the result of the previous step as the input to the next step.\n","function _uploadFilesContinue(outputId) {\n","  const outputElement = document.getElementById(outputId);\n","  const steps = outputElement.steps;\n","\n","  const next = steps.next(outputElement.lastPromiseValue);\n","  return Promise.resolve(next.value.promise).then((value) => {\n","    // Cache the last promise value to make it available to the next\n","    // step of the generator.\n","    outputElement.lastPromiseValue = value;\n","    return next.value.response;\n","  });\n","}\n","\n","/**\n"," * Generator function which is called between each async step of the upload\n"," * process.\n"," * @param {string} inputId Element ID of the input file picker element.\n"," * @param {string} outputId Element ID of the output display.\n"," * @return {!Iterable<!Object>} Iterable of next steps.\n"," */\n","function* uploadFilesStep(inputId, outputId) {\n","  const inputElement = document.getElementById(inputId);\n","  inputElement.disabled = false;\n","\n","  const outputElement = document.getElementById(outputId);\n","  outputElement.innerHTML = '';\n","\n","  const pickedPromise = new Promise((resolve) => {\n","    inputElement.addEventListener('change', (e) => {\n","      resolve(e.target.files);\n","    });\n","  });\n","\n","  const cancel = document.createElement('button');\n","  inputElement.parentElement.appendChild(cancel);\n","  cancel.textContent = 'Cancel upload';\n","  const cancelPromise = new Promise((resolve) => {\n","    cancel.onclick = () => {\n","      resolve(null);\n","    };\n","  });\n","\n","  // Wait for the user to pick the files.\n","  const files = yield {\n","    promise: Promise.race([pickedPromise, cancelPromise]),\n","    response: {\n","      action: 'starting',\n","    }\n","  };\n","\n","  cancel.remove();\n","\n","  // Disable the input element since further picks are not allowed.\n","  inputElement.disabled = true;\n","\n","  if (!files) {\n","    return {\n","      response: {\n","        action: 'complete',\n","      }\n","    };\n","  }\n","\n","  for (const file of files) {\n","    const li = document.createElement('li');\n","    li.append(span(file.name, {fontWeight: 'bold'}));\n","    li.append(span(\n","        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n","        `last modified: ${\n","            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n","                                    'n/a'} - `));\n","    const percent = span('0% done');\n","    li.appendChild(percent);\n","\n","    outputElement.appendChild(li);\n","\n","    const fileDataPromise = new Promise((resolve) => {\n","      const reader = new FileReader();\n","      reader.onload = (e) => {\n","        resolve(e.target.result);\n","      };\n","      reader.readAsArrayBuffer(file);\n","    });\n","    // Wait for the data to be ready.\n","    let fileData = yield {\n","      promise: fileDataPromise,\n","      response: {\n","        action: 'continue',\n","      }\n","    };\n","\n","    // Use a chunked sending to avoid message size limits. See b/62115660.\n","    let position = 0;\n","    do {\n","      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n","      const chunk = new Uint8Array(fileData, position, length);\n","      position += length;\n","\n","      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n","      yield {\n","        response: {\n","          action: 'append',\n","          file: file.name,\n","          data: base64,\n","        },\n","      };\n","\n","      let percentDone = fileData.byteLength === 0 ?\n","          100 :\n","          Math.round((position / fileData.byteLength) * 100);\n","      percent.textContent = `${percentDone}% done`;\n","\n","    } while (position < fileData.byteLength);\n","  }\n","\n","  // All done.\n","  yield {\n","    response: {\n","      action: 'complete',\n","    }\n","  };\n","}\n","\n","scope.google = scope.google || {};\n","scope.google.colab = scope.google.colab || {};\n","scope.google.colab._files = {\n","  _uploadFiles,\n","  _uploadFilesContinue,\n","};\n","})(self);\n","</script> "],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Saving predict.jpg to predict.jpg\n","Da tai len file : predict.jpg\n"]}],"source":["# Upload anh truc tiep\n","from google.colab import files\n","\n","upload = files.upload()\n","filename = next(iter(upload))\n","\n","print(f\"Da tai len file : {filename}\")"]},{"cell_type":"code","execution_count":21,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":5733,"status":"ok","timestamp":1699815872160,"user":{"displayName":"Dowis","userId":"18108172807253778035"},"user_tz":-420},"id":"r11qLchc6Zvt","outputId":"1550385d-8cfc-4ed8-e6d8-700d4e3283c0"},"outputs":[{"name":"stdout","output_type":"stream","text":["Ultralytics YOLOv8.0.208 🚀 Python-3.10.12 torch-2.1.0+cu118 CUDA:0 (Tesla T4, 15102MiB)\n","Model summary (fused): 168 layers, 11125971 parameters, 0 gradients, 28.4 GFLOPs\n","\n","image 1/1 /content/drive/MyDrive/predict.jpg: 384x640 8 Humans, 112.0ms\n","Speed: 3.1ms preprocess, 112.0ms inference, 77.2ms postprocess per image at shape (1, 3, 384, 640)\n","Results saved to \u001b[1mruns/detect/predict2\u001b[0m\n","💡 Learn more at https://docs.ultralytics.com/modes/predict\n"]}],"source":["# Predict with CLI\n","!yolo task=detect mode=predict model=/content/drive/MyDrive/nkduyen/runs/detect/train3/weights/best.pt source='/content/drive/MyDrive/predict.jpg'"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"e83jkKOT7Ug-"},"outputs":[],"source":["# Predict with python API\n","from ultralytics import YOLO\n","\n","model = YOLO(\"/content/drive/MyDrive/runs/detect/train5/weights/best.pt\")\n","results = model.predict(show=true, source=\"0\") #source='/content/drive/MyDrive/predict.jpg'"]},{"cell_type":"markdown","metadata":{"id":"wHt6BykMGQsd"},"source":["# 7.Export Model"]},{"cell_type":"code","execution_count":22,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":17361,"status":"ok","timestamp":1699816209065,"user":{"displayName":"Dowis","userId":"18108172807253778035"},"user_tz":-420},"id":"rLwS9CiL7_Qq","outputId":"a9599147-1427-443d-de12-18c619688f03"},"outputs":[{"name":"stdout","output_type":"stream","text":["Ultralytics YOLOv8.0.208 🚀 Python-3.10.12 torch-2.1.0+cu118 CPU (Intel Xeon 2.20GHz)\n","Model summary (fused): 168 layers, 11125971 parameters, 0 gradients, 28.4 GFLOPs\n","\n","\u001b[34m\u001b[1mPyTorch:\u001b[0m starting from '/content/drive/MyDrive/runs/detect/train5/weights/best.pt' with input shape (1, 3, 640, 640) BCHW and output shape(s) (1, 5, 8400) (21.4 MB)\n","\u001b[31m\u001b[1mrequirements:\u001b[0m Ultralytics requirement ['onnx>=1.12.0'] not found, attempting AutoUpdate...\n","Collecting onnx>=1.12.0\n","  Downloading onnx-1.15.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (15.7 MB)\n","     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 15.7/15.7 MB 95.1 MB/s eta 0:00:00\n","Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from onnx>=1.12.0) (1.23.5)\n","Requirement already satisfied: protobuf>=3.20.2 in /usr/local/lib/python3.10/dist-packages (from onnx>=1.12.0) (3.20.3)\n","Installing collected packages: onnx\n","Successfully installed onnx-1.15.0\n","\n","\u001b[31m\u001b[1mrequirements:\u001b[0m AutoUpdate success ✅ 9.0s, installed 1 package: ['onnx>=1.12.0']\n","\u001b[31m\u001b[1mrequirements:\u001b[0m ⚠️ \u001b[1mRestart runtime or rerun command for updates to take effect\u001b[0m\n","\n","\n","\u001b[34m\u001b[1mONNX:\u001b[0m starting export with onnx 1.15.0 opset 17...\n","\u001b[34m\u001b[1mONNX:\u001b[0m export success ✅ 11.0s, saved as '/content/drive/MyDrive/runs/detect/train5/weights/best.onnx' (42.6 MB)\n","\n","Export complete (14.1s)\n","Results saved to \u001b[1m/content/drive/MyDrive/runs/detect/train5/weights\u001b[0m\n","Predict:         yolo predict task=detect model=/content/drive/MyDrive/runs/detect/train5/weights/best.onnx imgsz=640  \n","Validate:        yolo val task=detect model=/content/drive/MyDrive/runs/detect/train5/weights/best.onnx imgsz=640 data=/content/drive/MyDrive/human_detection_dataset/data.yaml  \n","Visualize:       https://netron.app\n","💡 Learn more at https://docs.ultralytics.com/modes/export\n"]}],"source":["# Chuyen file weights thanh dang khac\n","!yolo export model=/content/drive/MyDrive/runs/detect/train5/weights/best.pt format=onnx"]}],"metadata":{"accelerator":"GPU","colab":{"authorship_tag":"ABX9TyNqGSd+y7+5yq4FpE3y3ouK","gpuType":"T4","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}
